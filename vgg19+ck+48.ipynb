{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Your machine learning code using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "zip_file_path = '/content/CK+48.zip'  # Path to the uploaded zip file in Colab\n",
    "extracted_dir_path = '/content/extracted/'  # Adjust the target directory in Colab\n",
    "\n",
    "# Unzip the file\n",
    "!unzip -q \"$zip_file_path\" -d \"$extracted_dir_path\"\n",
    "\n",
    "print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG19\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of emotions to numerical labels\n",
    "emotion_to_label = {'anger': 0, 'contempt': 1, 'disgust': 2, 'fear': 3, 'happy': 4, 'sadness': 5, 'surprise': 6}\n",
    "label_to_text = {0: 'anger', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happy', 5: 'sadness', 6: 'surprise'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "INPUT_PATH = \"/content/extracted/CK+48/\"\n",
    "\n",
    "# Count the total number of images\n",
    "total_images = sum(len(os.listdir(os.path.join(INPUT_PATH, dir_))) for dir_ in emotion_to_label.keys())\n",
    "\n",
    "# Initialize arrays for images and labels\n",
    "img_arr = np.empty(shape=(total_images, 224, 224, 3))\n",
    "img_label = np.empty(shape=(total_images))\n",
    "\n",
    "# Initialize counters for indexing\n",
    "idx = 0\n",
    "\n",
    "for emotion, label_value in emotion_to_label.items():\n",
    "    dir_path = os.path.join(INPUT_PATH, emotion)\n",
    "    for f in os.listdir(dir_path):\n",
    "        img_path = os.path.join(dir_path, f)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "        img_arr[idx] = img_resized\n",
    "        img_label[idx] = label_value\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the VGG19 model with fine-tuning\n",
    "def build_vgg19(input_shape, num_classes):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Fine-tuning: unfreeze some top layers\n",
    "    for layer in base_model.layers[:-8]:  # Unfreeze last 8 layers\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Add dropout for regularization\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x, name=\"VGG19_emotion\")\n",
    "    return model\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 80\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the VGG19 model\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "model = build_vgg19(input_shape=INPUT_SHAPE, num_classes=len(label_to_text))\n",
    "\n",
    "# Compile the model\n",
    "optim = Adam(0.0001)  # Lower learning rate\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define EarlyStopping and ReduceLROnPlateau callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=15,  # Increased patience\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    factor=0.4,\n",
    "    patience=8,  # Increased patience\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, lr_scheduler]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_test, y_test),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions from the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "predicted_emotions = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(predicted_emotions, bins=np.arange(len(label_to_text) + 1), edgecolor='black', alpha=0.7)\n",
    "plt.xticks(range(len(label_to_text)), label_to_text.values(), rotation=45)\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Predicted Emotions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), predicted_emotions)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_to_text.values(),\n",
    "            yticklabels=label_to_text.values())\n",
    "plt.xlabel('Predicted Emotion')\n",
    "plt.ylabel('Actual Emotion')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate precision, recall, F1-score\n",
    "print(classification_report(np.argmax(y_test, axis=1), predicted_emotions,\n",
    "                            target_names=label_to_text.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curves and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {label_to_text[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Replace 'other_model_val_accuracy' with the accuracy values of another model\n",
    "other_model_val_accuracy = [...]  # Replace this with actual accuracy values\n",
    "\n",
    "# Make sure both arrays have the same length\n",
    "max_length = max(len(history.history['val_accuracy']), len(other_model_val_accuracy))\n",
    "history_val_accuracy_padded = np.pad(history.history['val_accuracy'], (0, max_length - len(history.history['val_accuracy'])), mode='constant', constant_values=np.nan)\n",
    "other_model_val_accuracy_padded = np.pad(other_model_val_accuracy, (0, max_length - len(other_model_val_accuracy)), mode='constant', constant_values=np.nan)\n",
    "\n",
    "# Perform paired t-test\n",
    "t_statistic, p_value = ttest_rel(history_val_accuracy_padded, other_model_val_accuracy_padded)\n",
    "\n",
    "# Define the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in performance is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in performance is not statistically significant.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
